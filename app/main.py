import time
from fastapi import FastAPI, Query
from fastapi.responses import JSONResponse
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import urllib.parse
import requests

# ì´ˆê¸° í´ë¡  pip install poetry
# poetry install === npm i (íŒ€ì› ê°ì ê°€ìƒí™˜ê²½ ë§Œë“¤ì–´ì•¼ í•¨)
# ì„œë²„ í‚¤ëŠ” ëª…ë ¹ì–´ poetry run uvicorn app.main:app --reload (= FastAPI ì‹¤í–‰)

app = FastAPI()

BASE_URL = "https://www.diningcode.com"

# def get_restaurants(keyword: str):
#     search_url = f"{BASE_URL}/list.dc?query={urllib.parse.quote(keyword)}"
#     headers = {
#         "User-Agent": (
#             "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
#             "AppleWebKit/537.36 (KHTML, like Gecko) "
#             "Chrome/124.0.0.0 Safari/537.36"
#         )
#     }
#     print(f"ê²€ìƒ‰ URL: {search_url}")
#     res = requests.get(search_url, headers=headers)
#     print(f"HTTP Status: {res.status_code}")
#     res.raise_for_status()
#     print("HTML ë‚´ìš© ì¼ë¶€:", res.text[:500])  # ì²˜ìŒ 500ìë§Œ ë¯¸ë¦¬ë³´ê¸°

#     with open("debug.html", "w", encoding="utf-8") as f:
#         f.write(res.text)
#     print("debug.html ì €ì¥ ì™„ë£Œ")

#     soup = BeautifulSoup(res.text, "html.parser")
#     restaurants = []
#     for idx, a_tag in enumerate(soup.select("a.PoiBlock")):
#         href = a_tag.get("href", "")
#         print(f"{idx}ë²ˆì§¸ a.PoiBlock href: {href}")
#         if "/profile.php?rid=" not in href:
#             continue
#         rid = urllib.parse.parse_qs(urllib.parse.urlparse(href).query).get("rid", [None])[0]
#         name_tag = a_tag.select_one("h2")
#         name = name_tag.get_text(strip=True) if name_tag else "ì´ë¦„ ì—†ìŒ"
#         print(f"ì‹ë‹¹ ë°œê²¬: name={name}, rid={rid}")
#         restaurants.append({"name": name, "rid": rid})

#     print(f"ì´ {len(restaurants)}ê°œ ì‹ë‹¹ íƒìƒ‰ë¨")
#     return restaurants

# def get_menu_from_profile(rid: str):
#     url = f"{BASE_URL}/profile.php?rid={rid}"
#     print(f"[ë©”ë‰´ í¬ë¡¤ë§ ì‹œë„: {url}")

#     options = Options()
#     options.add_argument("--headless")
#     options.add_argument("--no-sandbox")
#     options.add_argument("--disable-dev-shm-usage")
#     driver = webdriver.Chrome(options=options)

#     try:
#         driver.get(url)
#         print("Selenium í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
#         WebDriverWait(driver, 10).until(
#             EC.presence_of_element_located((By.CSS_SELECTOR, "ul.Restaurant_MenuList"))
#         )

#         name = driver.find_element(By.CSS_SELECTOR, "h2").text.strip()
#         menu_items = driver.find_elements(By.CSS_SELECTOR, "ul.Restaurant_MenuList li")
#         menus = []

#         for idx, item in enumerate(menu_items):
#             try:
#                 menu_name = item.find_element(By.CSS_SELECTOR, "span.Restaurant_Menu").text.strip()
#             except Exception as e:
#                 menu_name = ""
#                 print(f"{idx}ë²ˆì§¸ ë©”ë‰´ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
#             try:
#                 menu_price = item.find_element(By.CSS_SELECTOR, "p.Restaurant_MenuPrice").text.strip()
#             except Exception as e:
#                 menu_price = ""
#                 print(f"{idx}ë²ˆì§¸ ë©”ë‰´ê°€ê²© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
#             if menu_name or menu_price:
#                 menus.append(f"{menu_name} {menu_price}".strip())

#         print(f"ë©”ë‰´ ê°œìˆ˜: {len(menus)}")
#         return name, "\n".join(menus) if menus else "ë©”ë‰´ ì •ë³´ ì—†ìŒ"

#     except Exception as e:
#         print(f"ë©”ë‰´ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
#         return "ì—ëŸ¬", f"ë©”ë‰´ í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}"

#     finally:
#         driver.quit()
#         print(" Selenium ë“œë¼ì´ë²„ ì¢…ë£Œ")

# @app.get("/scrape")
# def scrape_menus(keyword: str = Query(..., description="ê²€ìƒ‰í•  ì§€ì—­ëª… ë˜ëŠ” í‚¤ì›Œë“œ")):
#     print(f"/scrape ì§„ì…, keyword={keyword}")
#     restaurants = get_restaurants(keyword)
#     result_lines = []

#     for r in restaurants:
#         if not r["rid"]:
#             print(f"rid ì—†ìŒ, ê±´ë„ˆëœ€: {r}")
#             continue
#         print(f"ë©”ë‰´ í¬ë¡¤ë§ ì‹œì‘: {r['name']} ({r['rid']})")
#         name, menus = get_menu_from_profile(r["rid"])
#         print(f"ë©”ë‰´ í¬ë¡¤ë§ ì™„ë£Œ: {name}")
#         result_lines.append(f"[{name}]\n{menus}\n")

#     with open("menus.txt", "w", encoding="utf-8") as f:
#         f.write("\n".join(result_lines))
#     print(f"menus.txt ì €ì¥ ì™„ë£Œ ({len(result_lines)}ê°œ ì‹ë‹¹)")

#     return {"msg": f"{len(result_lines)}ê°œ ì‹ë‹¹ì˜ ë©”ë‰´ ì •ë³´ë¥¼ menus.txtì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."}


# í‚¤ì›Œë“œ ê²€ìƒ‰ í•¨ìˆ˜
def get_restaurants_via_api(keyword: str):
    print("[INFO] API ë°©ì‹ìœ¼ë¡œ ì‹ë‹¹ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
    page = 1
    size = 20
    result = []
    MAX_PAGE = 200  # ğŸ”’ ì—¬ê¸°ì— ìµœëŒ€ í˜ì´ì§€ ì œí•œ ì¶”ê°€!

    while page <= MAX_PAGE:
        url = "https://im.diningcode.com/API/isearch/"
        headers = {
            "User-Agent": "Mozilla/5.0",
            "Content-Type": "application/x-www-form-urlencoded",
            "Origin": "https://www.diningcode.com",
            "Referer": "https://www.diningcode.com/"
        }
        data = {
            "query": keyword,
            "page": str(page),
            "size": str(size),
            "order": "r_score",
            "rn_search_flag": "on",
            "search_type": "poi_search",
        }

        res = requests.post(url, headers=headers, data=data)
        if res.status_code != 200:
            print(f"[ERROR] ìš”ì²­ ì‹¤íŒ¨: {res.status_code}")
            break

        json_data = res.json()
        items = json_data.get("result_data", {}).get("poi_section", {}).get("list", [])
        print(f"[INFO] {page}í˜ì´ì§€: {len(items)}ê°œ ìˆ˜ì§‘")

        if not items:
            print("[INFO] ë” ì´ìƒ ë°ì´í„° ì—†ìŒ, ìˆ˜ì§‘ ì¢…ë£Œ")
            break

        for item in items:
            result.append({
                "name": item.get("nm"),
                "addr": item.get("addr"),
                "cate": item.get("cate"),
                "score": item.get("score"),
                "v_rid": item.get("v_rid"),
            })

        page += 1

    print(f"[INFO] ì´ {len(result)}ê°œ ì‹ë‹¹ ìˆ˜ì§‘ ì™„ë£Œ (ìµœëŒ€ {MAX_PAGE} í˜ì´ì§€)")
    return result


@app.get("/restaurants")
def get_restaurants(keyword: str = Query(..., description="ê²€ìƒ‰í•  í‚¤ì›Œë“œ")):
    try:
        return get_restaurants_via_api(keyword)
    except Exception as e:
        print(f"[ERROR] í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        return JSONResponse(status_code=500, content={"message": "í¬ë¡¤ë§ ì‹¤íŒ¨", "detail": str(e)})